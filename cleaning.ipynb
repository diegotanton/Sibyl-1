{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load and Clean Data\n",
    "\n",
    "raw = pd.read_csv(\"data/wilshire_052924.csv\")\n",
    "rawn = raw.copy().dropna(subset=\"Ticker\")\n",
    "rawn[\"Market Cap ($M)\"] = raw[\"Market Cap ($M)\"].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "\n",
    "corps = rawn[(rawn[\"Market Cap ($M)\"] >= 20)][[\"Ticker\", \"Name\", \"Sector\", \"Market Cap ($M)\"]] \\\n",
    "    .drop_duplicates(subset=\"Name\") \\\n",
    "    .rename(columns={\"Market Cap ($M)\": \"Cap\"}) \\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaned Company Names\n",
    "\n",
    "companies = [\n",
    "    re.sub(r\"\\([^)]*\\)\", \"\", str(company))\n",
    "    .replace(\",\", \"\")\n",
    "    .replace(\".\", \"\")\n",
    "    .replace(\"`\", \"'\") + \" \"\n",
    "    for company in corps[\"Name\"].values\n",
    "]\n",
    "\n",
    "# Create composite regex pattern\n",
    "patterns = [\n",
    "    \"incorporated\",\n",
    "    \"corporation\",\n",
    "    \"company\",\n",
    "    \"companies\",\n",
    "    \"holdings\",\n",
    "    \"holding\",\n",
    "    \" inc \",\n",
    "    \" corp \",\n",
    "    \" & co \",\n",
    "    \" co \",\n",
    "    \" plc \",\n",
    "    \" llc \",\n",
    "    \" ltd \"\n",
    "]\n",
    "regex_pattern = '|'.join(re.escape(pattern) for pattern in patterns)\n",
    "\n",
    "# Create cleaned names list\n",
    "cleaned = [re.sub(regex_pattern, \"\", company, flags=re.IGNORECASE).strip() for company in companies]\n",
    "\n",
    "# Handle exceptions\n",
    "cleaned[cleaned.index(\"Church & DwightInc\")] = \"Church & Dwight\"\n",
    "cleaned[cleaned.index(\"American Water WorksInc\")] = \"American Water Works\"\n",
    "cleaned[cleaned.index(\"Best BuyInc\")] = \"Best Buy\"\n",
    "cleaned[cleaned.index(\"TREXInc\")] = \"TREX\"\n",
    "cleaned[cleaned.index(\"DonaldsonInc\")] = \"Donaldson\"\n",
    "cleaned[cleaned.index(\"Simpson ManufacturingInc\")] = \"Simpson Manufacturing\"\n",
    "cleaned[cleaned.index(\"MSC Industrial DirectInc\")] = \"MSC Industrial Direct\"\n",
    "cleaned[cleaned.index(\"Franklin ElectricInc\")] = \"Franklin Electric\"\n",
    "cleaned[cleaned.index(\"Boston BeerInc\")] = \"Boston Beer\"\n",
    "cleaned[cleaned.index(\"GannettInc\")] = \"Gannett\"\n",
    "cleaned[cleaned.index(\"ManitowocInc\")] = \"Manitowoc\"\n",
    "cleaned[cleaned.index(\"Maui Land & PineappleInc\")] = \"Maui Land & Pineapple\"\n",
    "cleaned[cleaned.index(\"LannettInc\")] = \"Lannett\"\n",
    "cleaned[cleaned.index(\"MerckInc\")] = \"Merck\"\n",
    "cleaned[cleaned.index(\"KKRInc\")] = \"KKR\"\n",
    "cleaned[cleaned.index(\"McCormickInc\")] = \"McCormick\"\n",
    "cleaned[cleaned.index(\"Sturm RugerInc\")] = \"Sturm Ruger\"\n",
    "cleaned[cleaned.index(\"GreenhillInc\")] = \"Greenhill\"\n",
    "cleaned[cleaned.index(\"Comstock Inc\")] = \"Comstock\"\n",
    "cleaned[cleaned.index(\"Team\")] = \"Team Inc\"\n",
    "cleaned[cleaned.index(\"Dow\")] = \"Dow Inc\"\n",
    "cleaned[cleaned.index(\"Visa\")] = \"Visa Inc\"\n",
    "cleaned[cleaned.index(\"Amazoncom\")] = \"Amazon\"\n",
    "cleaned[cleaned.index(\"Alarmcom\")] = \"Alarm.com\"\n",
    "cleaned[cleaned.index(\"Carscom\")] = \"Cars.com\"\n",
    "cleaned[cleaned.index(\"1-800 Flowerscom\")] = \"1-800 Flowers.com\"\n",
    "cleaned[cleaned.index(\"CarPartscom\")] = \"CarParts.com\"\n",
    "cleaned[cleaned.index(\"Lilly\")] = \"Eli Lilly\"\n",
    "cleaned[cleaned.index(\"Meta Platforms\")] = \"Meta\"\n",
    "cleaned[cleaned.index(\"Uber Technologies\")] = \"Uber\"\n",
    "cleaned[cleaned.index(\"Chipotle Mexican Grill\")] = \"Chipotle\"\n",
    "cleaned[cleaned.index(\"Skechers U S A\")] = \"Skechers USA\"\n",
    "cleaned[cleaned.index(\"Sanfilippo  & Son\")] = \"John B Sanfilippo & Son\"\n",
    "cleaned[cleaned.index(\"Lowe's Cos\")] = \"Lowe's\"\n",
    "cleaned[cleaned.index(\"Marsh & McLennan Cos\")] = \"Marsh & McLennan\"\n",
    "cleaned[cleaned.index(\"Williams Cos\")] = \"Williams\"\n",
    "cleaned[cleaned.index(\"Estee Lauder Cos\")] = \"Estee Lauder\"\n",
    "cleaned[cleaned.index(\"Greenbrier Cos\")] = \"Greenbrier\"\n",
    "cleaned[cleaned.index(\"Haverty Furniture Cos\")] = \"Haverty Furniture\"\n",
    "cleaned[cleaned.index(\"Kingstone Cos\")] = \"Kingstone\"\n",
    "cleaned[cleaned.index(\"Noodles &\")] = \"Noodles & Company\"\n",
    "cleaned[cleaned.index(\"Superior Group of\")] = \"Superior Group of Companies\"\n",
    "\n",
    "corps[\"NameCln\"] = cleaned\n",
    "corps.to_csv(\"data/corps.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually Search Output\n",
    "\n",
    "with open(\"cleaning.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group by Sectors and Save\n",
    "\n",
    "industrials = corps[(corps[\"Sector\"]==\"Industrials\") | (corps[\"Sector\"]==\"Basic Materials\")].reset_index(drop=True)\n",
    "healthcare = corps[(corps[\"Sector\"]==\"Healthcare\")].reset_index(drop=True)\n",
    "finance = corps[(corps[\"Sector\"]==\"Financial Services\") | (corps[\"Sector\"]==\"Real Estate\")].reset_index(drop=True)\n",
    "tech = corps[(corps[\"Sector\"]==\"Technology\") | (corps[\"Sector\"]==\"Communication Services\")].reset_index(drop=True)\n",
    "consumer = corps[(corps[\"Sector\"]==\"Consumer Cyclical\") | (corps[\"Sector\"]==\"Consumer Defensive\")].reset_index(drop=True)\n",
    "energy = corps[(corps[\"Sector\"]==\"Energy\") | (corps[\"Sector\"]==\"Utilities\")].reset_index(drop=True)\n",
    "\n",
    "names = [\"industrials\", \"healthcare\", \"finance\", \"tech\", \"consumer\", \"energy\"]\n",
    "\n",
    "for corp in names:\n",
    "    df = globals()[corp]\n",
    "    df.to_csv(f\"data/corps/{corp}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data Frames\n",
    "\n",
    "names = [\"industrials\", \"healthcare\", \"finance\", \"tech\", \"consumer\", \"energy\"]\n",
    "\n",
    "for corp in names:\n",
    "    exec(f\"{corp} = pd.read_csv('data/corps/{corp}.csv')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sibyl-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
